{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# camille: '/content/drive/MyDrive/Research/TAVA/TAVA-NN/codebase/paralang-vc'\n","# koye: './drive/MyDrive/TAVA-NN/codebase/paralang-vc'\n","\n","%cd '/content/drive/MyDrive/Research/TAVA/TAVA-NN/codebase/paralang-vc'\n","!ls\n","!pip install -q crepe\n","!pip install -q librosa\n","!chmod +x train.py #maybe have to do this every time, maybe not."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nlYsDzI-KVoy","executionInfo":{"status":"ok","timestamp":1677265270091,"user_tz":480,"elapsed":94494,"user":{"displayName":"Camille Noufi","userId":"04628122647747040750"}},"outputId":"87fefe14-cc24-4186-ec7d-0cd056d10e4a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Research/TAVA/TAVA-NN/codebase/paralang-vc\n","data.py     model_vc.py    __pycache__\t     testing.ipynb\n","example     outputs\t   README.md\t     test_input.ipynb\n","hp.py\t    package.py\t   requirements.txt  train.py\n","hubconf.py  plot_utils.py  spec_utils.py     train_wrapper.ipynb\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.4/323.4 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.1/217.1 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for crepe (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for resampy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["# run training script via command line\n","!python3 train.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iAXMdrElKTr0","executionInfo":{"status":"ok","timestamp":1677274309638,"user_tz":480,"elapsed":40996,"user":{"displayName":"Camille Noufi","userId":"04628122647747040750"}},"outputId":"1bb4a64e-c043-4629-f70f-9f8076fd7779"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["[BACKEND] Setting up paths and training.\n","[DATA] Found a total of 33 speakers\n","[SPEAKER EMBEDDING] Precomputing/identifying speaker embeddings\n","Using cache found in /root/.cache/torch/hub/RF5_simple-speaker-embedding_master\n","[SPEAKER EMBEDDING] Precomputing/identifying speaker embeddings\n","[DATA] Split into 30 train speakers (2192 files)\n","[DATA] and 3 test speakers (240 files)\n","[DATA] Constructing final dataloaders\n","  Num Train samples: 2192\n","  Num Test samples: 240\n","[LOGGING] Setting up logger\n","2023-02-24 21:31:16.441551: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-24 21:31:18.152295: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-02-24 21:31:18.152565: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-02-24 21:31:18.152595: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","[MODEL] Setting up model\n","[TRAIN] Beginning training\n","--------------- Epoch 0--------------------\n","2023-02-24 21:31:21.345657: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","8/8 [==============================] - 14s 2s/step\n","1/6 [====>.........................] - ETA: 8sTraceback (most recent call last):\n","  File \"train.py\", line 237, in <module>\n","    train(args)\n","  File \"train.py\", line 105, in train\n","    for i, (x_src, x_tgt, s_src, f0_src, amp_src) in enumerate(train_dl):\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 628, in __next__\n","    data = self._next_data()\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 671, in _next_data\n","    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/content/drive/MyDrive/Research/TAVA/TAVA-NN/codebase/paralang-vc/data.py\", line 71, in __getitem__\n","    _, f0, _, _ = crepe.predict(x_src, fs, viterbi=True, step_size=step_size)\n","  File \"/usr/local/lib/python3.8/dist-packages/crepe/core.py\", line 255, in predict\n","    activation = get_activation(audio, sr, model_capacity=model_capacity,\n","  File \"/usr/local/lib/python3.8/dist-packages/crepe/core.py\", line 212, in get_activation\n","    return model.predict(frames, verbose=verbose)\n","  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 2350, in predict\n","    tmp_batch_outputs = self.predict_function(iterator)\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 880, in __call__\n","    result = self._call(*args, **kwds)\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 919, in _call\n","    results = self._variable_creation_fn(*args, **kwds)\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 134, in __call__\n","    return concrete_function._call_flat(\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1745, in _call_flat\n","    return self._build_call_outputs(self._inference_function.call(\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 378, in call\n","    outputs = execute.execute(\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\", line 52, in quick_execute\n","    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n","KeyboardInterrupt\n","^C\n"]}]},{"cell_type":"code","source":["!python3 train.py --checkpoint /content/drive/MyDrive/Research/TAVA/TAVA-NN/codebase/paralang-vc/outputs/test_run_022423/checkpoint_last.pth"],"metadata":{"id":"6FvyE18bscCw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wGpS1fQJshel"},"execution_count":null,"outputs":[]}]}