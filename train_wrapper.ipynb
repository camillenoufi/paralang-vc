{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# camille: '/content/drive/MyDrive/Research/TAVA/TAVA-NN/codebase/paralang-vc'\n","# koye: \n","%cd '/content/drive/MyDrive/Research/TAVA/TAVA-NN/codebase/paralang-vc'\n","!ls\n","!pip install -q crepe\n","!chmod +x train.py #maybe have to do this every time, maybe not."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nlYsDzI-KVoy","executionInfo":{"status":"ok","timestamp":1677103894414,"user_tz":480,"elapsed":5834,"user":{"displayName":"Camille Noufi","userId":"04628122647747040750"}},"outputId":"79153803-a01e-4872-bcdf-b6adc3fc009e"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Research/TAVA/TAVA-NN/codebase/paralang-vc\n","data.py  hubconf.py   __pycache__\tspec_utils.py\t  train.py\n","example  model_vc.py  README.md\t\ttesting.ipynb\t  train_wrapper.ipynb\n","hp.py\t package.py   requirements.txt\ttest_input.ipynb\n"]}]},{"cell_type":"code","source":["# run training script like on the command line\n","!python3 train.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iAXMdrElKTr0","executionInfo":{"status":"ok","timestamp":1677103991110,"user_tz":480,"elapsed":30129,"user":{"displayName":"Camille Noufi","userId":"04628122647747040750"}},"outputId":"78f7e9d1-c0f9-42f2-8dc2-d5fb167a5f37"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[BACKEND] Setting up paths and training.\n","[DATA] Found a total of 22 speakers\n","[DATA] Split into 17 train speakers (271 files)\n","[DATA] and 5 test speakers (80 files)\n","/usr/local/lib/python3.8/dist-packages/torch/hub.py:267: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n","  warnings.warn(\n","Downloading: \"https://github.com/RF5/simple-speaker-embedding/zipball/master\" to /root/.cache/torch/hub/master.zip\n","Downloading: \"https://github.com/RF5/simple-speaker-embedding/releases/download/0.1/gru-wrapped-f1f850.pth\" to /root/.cache/torch/hub/checkpoints/gru-wrapped-f1f850.pth\n","100% 35.3M/35.3M [00:00<00:00, 62.0MB/s]\n","[SPEAKER EMBEDDING] Gathering speaker embeddings\n","[DATA] Constructing final dataloaders\n","Traceback (most recent call last):\n","  File \"train.py\", line 249, in <module>\n","    train(args)\n","  File \"train.py\", line 97, in train\n","    print(list(train_dl))\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 628, in __next__\n","    data = self._next_data()\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 671, in _next_data\n","    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/content/drive/MyDrive/Research/TAVA/TAVA-NN/codebase/paralang-vc/data.py\", line 50, in __getitem__\n","    x, fs = librosa.load(pth, sr=hp.sample_rate)\n","AttributeError: type object 'hp' has no attribute 'sample_rate'\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"cNg6zjTEL5GP"},"execution_count":null,"outputs":[]}]}